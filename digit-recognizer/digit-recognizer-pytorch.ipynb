{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# digit-recognizer\n",
    "\n",
    "https://www.kaggle.com/competitions/digit-recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_KAGGLE = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "COMP_NAME = 'digit-recognizer'\n",
    "\n",
    "if COMP_NAME is None:\n",
    "    raise NameError('COMP_NAME has not been initialized')\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "DATA_PATH = Path('../input/' + COMP_NAME) if IS_KAGGLE else Path('./data')\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle: N\n",
      "torch version: 2.0.1\n",
      "device: cuda:0\n",
      "2 GPU(s) available\n"
     ]
    }
   ],
   "source": [
    "print('kaggle:', 'Y' if IS_KAGGLE else 'N')\n",
    "print('torch version:', torch.__version__)\n",
    "print('device:', DEVICE)\n",
    "print(torch.cuda.device_count(), 'GPU(s) available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "https://www.kaggle.com/competitions/digit-recognizer/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('./data')\n",
    "if not DATA_PATH.exists():\n",
    "    import zipfile, kaggle\n",
    "    kaggle.api.competition_download_cli(COMP_NAME)\n",
    "    zipfile.ZipFile(f'{COMP_NAME}.zip').extractall(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (42000, 785)\n",
      "test:  (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(DATA_PATH / 'train.csv')\n",
    "test_data = pd.read_csv(DATA_PATH / 'test.csv')\n",
    "\n",
    "print('train:', train_data.shape)\n",
    "print('test: ', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (42000, 784) <class 'pandas.core.frame.DataFrame'>\n",
      "y: (42000,) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = train_data.iloc[:, train_data.columns != 'label']\n",
    "y = train_data.label.values\n",
    "\n",
    "print('X:', X.shape, type(X))\n",
    "print('y:', y.shape, type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(8,8))\n",
    "cols, rows = 3, 3\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample = random.randint(0, len(X)-1)\n",
    "    label = str(int(y[sample]))\n",
    "    img = X.values[sample].reshape(28,28)\n",
    "    \n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training/Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (33600, 784) y_train: (33600,)\n",
      "X_valid: (8400, 784) y_valid: (8400,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "print('X_train:', X_train.shape, 'y_train:', y_train.shape)\n",
    "print('X_valid:', X_valid.shape, 'y_valid:', y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize (0-255 -> 0-1)\n",
    "\n",
    "X_train = X_train.values / 255\n",
    "X_valid = X_valid.values / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.dtype: torch.float64\n",
      "y_train.dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(X_train)\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "\n",
    "X_valid = torch.from_numpy(X_valid)\n",
    "y_valid = torch.from_numpy(y_valid).type(torch.LongTensor)\n",
    "\n",
    "print('X_train.dtype:', X_train.dtype)\n",
    "print('y_train.dtype:', y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "valid_ds = torch.utils.data.TensorDataset(X_valid, y_valid)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitRecognizerModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Architecture summary:\n",
    "      - Layer 1: Convolution 1 > Activation (ReLU) > Pooling 1 > Dropout 1\n",
    "      - Layer 2: Convolution 2 > Activation (ReLU) > Pooling 2 > Dropout 2 > Flatten\n",
    "      - Layer 3: Linear 1 > Activation (ReLU) > Dropout 3\n",
    "      - Layer 4: Linear 2 > Activation (ReLU) > Dropout 4\n",
    "      - Layer 5: Output > Activation (Softmax)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # layer 1 \n",
    "        # (black and white image, 1 color channel == 1 input channel)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=128, kernel_size=5, stride=1, padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.drop1 = nn.Dropout(p=0.3)\n",
    "\n",
    "        # layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=128, out_channels=224, kernel_size=5, stride=1, padding=0)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.drop2 = nn.Dropout(p=0.4)\n",
    "\n",
    "        # layer 3\n",
    "        self.linear1 = nn.Linear(in_features=224 * 4 * 4, out_features=64)\n",
    "        self.drop3 = nn.Dropout(p=0.4)\n",
    "\n",
    "        # layer 4\n",
    "        self.linear2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.drop4 = nn.Dropout(p=0.4)\n",
    "\n",
    "        # layer 5\n",
    "        self.linear3 = nn.Linear(in_features=32, out_features=10)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.drop1(self.pool1(F.relu(self.conv1(x)))) # layer 1\n",
    "        out = self.drop2(self.pool2(F.relu(self.conv2(out)))) # layer 2\n",
    "        out = out.view(-1, 224 * 4 * 4) # flatten layer 2 outputs since layer 3 is linear\n",
    "        \n",
    "        out = self.drop3(F.relu(self.linear1(out))) # layer 3\n",
    "        out = self.drop4(F.relu(self.linear2(out))) # layer 4\n",
    "        # out = self.softmax(self.linear3(out)) # layer 5\n",
    "        out = self.linear3(out) # logits\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DigitRecognizerModel(\n",
      "  (conv1): Conv2d(1, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (conv2): Conv2d(128, 224, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (drop2): Dropout(p=0.4, inplace=False)\n",
      "  (linear1): Linear(in_features=3584, out_features=64, bias=True)\n",
      "  (drop3): Dropout(p=0.4, inplace=False)\n",
      "  (linear2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (drop4): Dropout(p=0.4, inplace=False)\n",
      "  (linear3): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = DigitRecognizerModel().to(DEVICE)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape\n",
       "============================================================================================================================================\n",
       "DigitRecognizerModel                     [1, 28, 28]               [1, 10]                   --                        --\n",
       "├─Conv2d: 1-1                            [1, 28, 28]               [128, 24, 24]             3,328                     [5, 5]\n",
       "├─MaxPool2d: 1-2                         [128, 24, 24]             [128, 12, 12]             --                        [2, 2]\n",
       "├─Dropout: 1-3                           [128, 12, 12]             [128, 12, 12]             --                        --\n",
       "├─Conv2d: 1-4                            [128, 12, 12]             [224, 8, 8]               717,024                   [5, 5]\n",
       "├─MaxPool2d: 1-5                         [224, 8, 8]               [224, 4, 4]               --                        [2, 2]\n",
       "├─Dropout: 1-6                           [224, 4, 4]               [224, 4, 4]               --                        --\n",
       "├─Linear: 1-7                            [1, 3584]                 [1, 64]                   229,440                   --\n",
       "├─Dropout: 1-8                           [1, 64]                   [1, 64]                   --                        --\n",
       "├─Linear: 1-9                            [1, 64]                   [1, 32]                   2,080                     --\n",
       "├─Dropout: 1-10                          [1, 32]                   [1, 32]                   --                        --\n",
       "├─Linear: 1-11                           [1, 32]                   [1, 10]                   330                       --\n",
       "============================================================================================================================================\n",
       "Total params: 952,202\n",
       "Trainable params: 952,202\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.30\n",
       "============================================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.71\n",
       "Params size (MB): 3.81\n",
       "Estimated Total Size (MB): 4.52\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model, (1, 28, 28), col_names=('input_size', 'output_size', 'num_params', 'kernel_size'), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, print_every=100):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = (X.view(-1, 1, 28, 28)).type(torch.FloatTensor).to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        logits = model(X)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # print results\n",
    "        if batch % print_every == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_loop(dataloader, model, loss_fn, print_every=100):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    batches = len(dataloader)\n",
    "    loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = (X.view(-1, 1, 28, 28)).type(torch.FloatTensor).to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "\n",
    "            logits = model(X)\n",
    "            loss += loss_fn(logits, y).item()\n",
    "            correct += (logits.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    loss /= BATCH_SIZE\n",
    "    correct /= size\n",
    "    print(f'Validation: Accuracy={(100*correct):>0.1f}%, Average_Loss={loss:>8f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.290158 [  100/33600]\n",
      "loss: 0.779308 [10100/33600]\n",
      "loss: 0.512162 [20100/33600]\n",
      "loss: 0.319611 [30100/33600]\n",
      "Validation: Accuracy=96.8%, Average_Loss=0.101270\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.241113 [  100/33600]\n",
      "loss: 0.325025 [10100/33600]\n",
      "loss: 0.323316 [20100/33600]\n",
      "loss: 0.231328 [30100/33600]\n",
      "Validation: Accuracy=98.0%, Average_Loss=0.059262\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.176649 [  100/33600]\n",
      "loss: 0.190975 [10100/33600]\n",
      "loss: 0.303267 [20100/33600]\n",
      "loss: 0.130003 [30100/33600]\n",
      "Validation: Accuracy=98.4%, Average_Loss=0.050965\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.159528 [  100/33600]\n",
      "loss: 0.206334 [10100/33600]\n",
      "loss: 0.166055 [20100/33600]\n",
      "loss: 0.237737 [30100/33600]\n",
      "Validation: Accuracy=98.4%, Average_Loss=0.047184\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.318449 [  100/33600]\n",
      "loss: 0.061951 [10100/33600]\n",
      "loss: 0.081967 [20100/33600]\n",
      "loss: 0.245102 [30100/33600]\n",
      "Validation: Accuracy=98.8%, Average_Loss=0.036191\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.033406 [  100/33600]\n",
      "loss: 0.291876 [10100/33600]\n",
      "loss: 0.116702 [20100/33600]\n",
      "loss: 0.180537 [30100/33600]\n",
      "Validation: Accuracy=98.9%, Average_Loss=0.037230\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.141514 [  100/33600]\n",
      "loss: 0.244364 [10100/33600]\n",
      "loss: 0.115032 [20100/33600]\n",
      "loss: 0.142564 [30100/33600]\n",
      "Validation: Accuracy=98.9%, Average_Loss=0.030825\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.110536 [  100/33600]\n",
      "loss: 0.191458 [10100/33600]\n",
      "loss: 0.083834 [20100/33600]\n",
      "loss: 0.049157 [30100/33600]\n",
      "Validation: Accuracy=98.8%, Average_Loss=0.037714\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.077672 [  100/33600]\n",
      "loss: 0.125731 [10100/33600]\n",
      "loss: 0.047382 [20100/33600]\n",
      "loss: 0.107439 [30100/33600]\n",
      "Validation: Accuracy=99.0%, Average_Loss=0.027992\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.107419 [  100/33600]\n",
      "loss: 0.117339 [10100/33600]\n",
      "loss: 0.068992 [20100/33600]\n",
      "loss: 0.131308 [30100/33600]\n",
      "Validation: Accuracy=98.9%, Average_Loss=0.031416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch+1}\\n-------------------------------')\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    valid_loop(valid_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.values\n",
    "X_test = torch.from_numpy(X_test / 255)\n",
    "\n",
    "y_test = np.zeros(X_test.shape)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "test_ds = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_rows = [['ImageId', 'Label']]\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    image_id = 1\n",
    "\n",
    "    for X, _ in test_loader:\n",
    "        X = (X.view(-1, 1, 28, 28)).type(torch.FloatTensor).to(DEVICE)\n",
    "        preds = model(X).argmax(1)\n",
    "\n",
    "        for pred in preds:\n",
    "            submission_rows.append([image_id, pred.item()])\n",
    "            image_id += 1\n",
    "\n",
    "submission = pd.DataFrame(submission_rows)\n",
    "submission.columns = submission.iloc[0]\n",
    "submission = submission.drop(0, axis=0)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
